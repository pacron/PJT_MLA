{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation adversariale par rotation de x dans la direction du gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the model ---\n",
      "Epoch [1/20], Loss: 0.48311883651180815\n",
      "Epoch [2/20], Loss: 0.33656363570486814\n",
      "Epoch [3/20], Loss: 0.3140984530975697\n",
      "Epoch [4/20], Loss: 0.3020510265250196\n",
      "Epoch [5/20], Loss: 0.2942419885429365\n",
      "Epoch [6/20], Loss: 0.2884822124833745\n",
      "Epoch [7/20], Loss: 0.28421286724682554\n",
      "Epoch [8/20], Loss: 0.28113810275631673\n",
      "Epoch [9/20], Loss: 0.27834817867225675\n",
      "Epoch [10/20], Loss: 0.27526939525676053\n",
      "Epoch [11/20], Loss: 0.2733153218049993\n",
      "Epoch [12/20], Loss: 0.2714766095330847\n",
      "Epoch [13/20], Loss: 0.26983637878222505\n",
      "Epoch [14/20], Loss: 0.2684981512394287\n",
      "Epoch [15/20], Loss: 0.26724203368986466\n",
      "Epoch [16/20], Loss: 0.26556795752490125\n",
      "Epoch [17/20], Loss: 0.26436674071035027\n",
      "Epoch [18/20], Loss: 0.2638104881829163\n",
      "Epoch [19/20], Loss: 0.2623897121468587\n",
      "Epoch [20/20], Loss: 0.26208111754199587\n",
      "\n",
      "--- Testing on clean data ---\n",
      "Accuracy on clean data: 92.89666666666666%\n",
      "Average probability assigned to incorrect predictions (on clean data): 63.68%\n",
      "\n",
      "--- Testing on adversarial data ---\n",
      "Accuracy on adversarial examples: 79.57833333333333%\n",
      "Average probability assigned to incorrect predictions (on adversarial data): 66.55%\n",
      "\n",
      "--- Comparison ---\n",
      "Clean Data: Accuracy = 92.90%, Avg Confidence on Incorrect = 63.68%\n",
      "Adversarial Data: Accuracy = 79.58%, Avg Confidence on Incorrect = 66.55%\n"
     ]
    }
   ],
   "source": [
    "# @title version test, attaque adversarial par rotation de x dans la direction du gradient\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Définition de l'attaque adversarial\n",
    "def rotate_by_gradient(model, images, labels, epsilon):\n",
    "    images.requires_grad = True\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    gradients = images.grad\n",
    "\n",
    "    perturbation = epsilon * gradients / gradients.norm(p=2, dim=(1, 2, 3), keepdim=True)\n",
    "    adversarial_images = images + perturbation\n",
    "    adversarial_images = torch.clamp(adversarial_images, 0, 1)\n",
    "\n",
    "    return adversarial_images\n",
    "\n",
    "\n",
    "# Classe du modèle (shallow softmax classifier)\n",
    "class ShallowSoftmaxClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowSoftmaxClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Charger les données MNIST\n",
    "def load_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    full_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(full_dataset, batch_size=64, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "# Entraînement sur des données normales\n",
    "def train_on_normal_data(model, train_loader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Test sur des données normales\n",
    "def test_on_normal_data(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    incorrect_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            probs = nn.Softmax(dim=1)(outputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                if predicted[i] != labels[i]:\n",
    "                    incorrect_probs.append(probs[i, predicted[i]].item())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_incorrect_prob = np.mean(incorrect_probs) * 100 if incorrect_probs else 0\n",
    "    print(f\"Accuracy on clean data: {accuracy}%\")\n",
    "\n",
    "    \n",
    "    if incorrect_probs:\n",
    "        avg_incorrect_prob = np.mean(incorrect_probs) * 100\n",
    "        print(f'Average probability assigned to incorrect predictions (on clean data): {avg_incorrect_prob:.2f}%')\n",
    "    else:\n",
    "        avg_incorrect_prob = 0\n",
    "        print('No incorrect predictions to calculate average probability on clean data.')\n",
    "    return accuracy, avg_incorrect_prob\n",
    "\n",
    "# Test sur des données adversariales\n",
    "def test_on_adversarial_data(model, train_loader, epsilon):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    incorrect_probs = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "    \n",
    "        images = images.clone().detach().requires_grad_(True)\n",
    "\n",
    "        adversarial_images = rotate_by_gradient(model, images, labels, epsilon)\n",
    "\n",
    "        outputs = model(adversarial_images)\n",
    "        probs = nn.Softmax(dim=1)(outputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                incorrect_probs.append(probs[i, predicted[i]].item())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on adversarial examples: {accuracy}%')\n",
    "\n",
    "    if incorrect_probs:\n",
    "        avg_incorrect_prob = np.mean(incorrect_probs) * 100\n",
    "        print(f'Average probability assigned to incorrect predictions (on adversarial data): {avg_incorrect_prob:.2f}%')\n",
    "    else:\n",
    "        avg_incorrect_prob = 0\n",
    "        print('No incorrect predictions to calculate average probability on adversarial data.')\n",
    "    return accuracy, avg_incorrect_prob\n",
    "\n",
    "\n",
    "# Fonction principale\n",
    "def main():\n",
    "    # Paramètres\n",
    "    epsilon = 0.5  # Magnitude des perturbations adversariales\n",
    "    epochs = 20  # Nombre d'époques d'entraînement\n",
    "\n",
    "    train_loader = load_data()\n",
    "    test_loader = load_data()\n",
    "\n",
    "    model = ShallowSoftmaxClassifier()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    print(\"\\n--- Training the model ---\")\n",
    "    train_on_normal_data(model, train_loader, optimizer, epochs)\n",
    "\n",
    "    print(\"\\n--- Testing on clean data ---\")\n",
    "    clean_accuracy, clean_avg_incorrect_prob = test_on_normal_data(model, test_loader)\n",
    "\n",
    "    print(\"\\n--- Testing on adversarial data ---\")\n",
    "    adversarial_accuracy, adversarial_avg_incorrect_prob = test_on_adversarial_data(model, test_loader, epsilon)\n",
    "\n",
    "    print(\"\\n--- Comparison ---\")\n",
    "    print(f\"Clean Data: Accuracy = {clean_accuracy:.2f}%, Avg Confidence on Incorrect = {clean_avg_incorrect_prob:.2f}%\")\n",
    "    print(f\"Adversarial Data: Accuracy = {adversarial_accuracy:.2f}%, Avg Confidence on Incorrect = {adversarial_avg_incorrect_prob:.2f}%\")\n",
    "\n",
    "# Exécuter la fonction principale\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
